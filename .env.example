# LLM Provider Configuration
# Choose your LLM provider: "openai" or "anthropic"
LLM_PROVIDER=openai

# OpenAI API Configuration
# Required when LLM_PROVIDER=openai
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic API Configuration
# Required when LLM_PROVIDER=anthropic
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# Note: Set this variable to run Anthropic integration tests
# Run tests with: pytest -m anthropic

# Data Provider API Keys
ALPHA_VANTAGE_API_KEY=your_alpha_vantage_api_key_here
# TRADIER_API_KEY=your_tradier_api_key_here

# LLM Model Configuration (OpenAI)
# Use GPT-4o for critical decision-making agents
PREMIUM_MODEL=gpt-4o
# Use GPT-4o-mini for routine analysis tasks
STANDARD_MODEL=gpt-4o-mini

# LLM Model Configuration (Anthropic)
# Use Claude 3.5 Sonnet for both critical and routine tasks
# ANTHROPIC_PREMIUM_MODEL=claude-3-5-sonnet-20241022
# ANTHROPIC_STANDARD_MODEL=claude-3-5-sonnet-20241022

# Memory Configuration
# Vector Database (ChromaDB)
CHROMA_PERSIST_DIRECTORY=./data/chroma_db

# SQL Database for Episodic Memory
DATABASE_URL=sqlite:///./data/episodic_memory.db
# For production, use PostgreSQL:
# DATABASE_URL=postgresql://user:password@localhost:5432/shri_sudarshan

# Redis Configuration (Optional - for distributed working memory)
# REDIS_HOST=localhost
# REDIS_PORT=6379
# REDIS_DB=0

# System Configuration
LOG_LEVEL=INFO
ENVIRONMENT=development

# Risk Management Parameters
MAX_POSITION_SIZE=0.05  # 5% of portfolio per position
MAX_PORTFOLIO_RISK=0.02  # 2% portfolio risk (VaR threshold)
MAX_SECTOR_CONCENTRATION=0.25  # 25% max in any sector

# Execution Configuration
PAPER_TRADING=true
BROKER_API_ENDPOINT=https://api.example-broker.com
# BROKER_API_KEY=your_broker_api_key_here

# Agent Configuration
ENABLE_CONCURRENT_ANALYSIS=true
MAX_DEBATE_ROUNDS=3
ANALYSIS_TIMEOUT_SECONDS=30

# Data Configuration
MARKET_DATA_CACHE_TTL=300  # 5 minutes
NEWS_LOOKBACK_DAYS=7
HISTORICAL_DATA_PERIOD=1y
